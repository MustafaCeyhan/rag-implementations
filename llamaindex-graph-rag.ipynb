{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.indices.knowledge_graph import KnowledgeGraphIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to see the processing steps / İşleme adımlarını görmek için günlükleme ayarla\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a graph-based RAG system using LlamaIndex\n",
    "\n",
    "Args:\n",
    "    data_dir: Directory containing the text files\n",
    "    persist_dir: Directory to save the index\n",
    "    rebuild: Whether to rebuild the index or load from storage\n",
    "    \n",
    "Returns:\n",
    "    kg_index: Knowledge graph\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_rag(data_dir=\"data\", persist_dir=\"storage\", rebuild=False):\n",
    "    \"\"\"\n",
    "    Build a graph-based RAG system using LlamaIndex\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory containing the text files\n",
    "        persist_dir: Directory to save the index\n",
    "        rebuild: Whether to rebuild the index or load from storage\n",
    "        \n",
    "    Returns:\n",
    "        kg_index: Knowledge graph\n",
    "    \"\"\"\n",
    "    # Initialize the LLM / LLM'i başlat\n",
    "    llm = OpenAI(model=\"gpt-4\")\n",
    "    # Update global settings / Genel ayarları güncelle\n",
    "    Settings.llm = llm\n",
    "    Settings.chunk_size = 1024\n",
    "    \n",
    "    # Check if we need to build or load the index\n",
    "    # İndeksin oluşturulup oluşturulmayacağını veya yükleneceğini kontrol et\n",
    "    if not os.path.exists(persist_dir) or rebuild:\n",
    "        print(f\"Building new index from {data_dir}... / {data_dir} dizininden yeni indeks oluşturuluyor...\")\n",
    "        \n",
    "        # Load documents from the directory / Dizin içindeki belgeleri yükle\n",
    "        if not os.path.exists(data_dir):\n",
    "            raise FileNotFoundError(f\"Data directory {data_dir} not found / Veri dizini {data_dir} bulunamadı\")\n",
    "            \n",
    "        documents = SimpleDirectoryReader(data_dir).load_data()\n",
    "        print(f\"Loaded {len(documents)} documents from {data_dir} / {data_dir} dizininden {len(documents)} belge yüklendi\")\n",
    "        \n",
    "        # Create a graph store / Bir grafik deposu oluştur\n",
    "        graph_store = SimpleGraphStore()\n",
    "        storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "        \n",
    "        # Build the knowledge graph index / Bilgi grafiği indeksini oluştur\n",
    "        kg_index = KnowledgeGraphIndex.from_documents(\n",
    "            documents,\n",
    "            storage_context=storage_context,\n",
    "            max_triplets_per_chunk=10,\n",
    "            include_embeddings=True,\n",
    "        )\n",
    "        \n",
    "        # Persist the indices / İndeksleri kalıcı hale getir\n",
    "        os.makedirs(persist_dir, exist_ok=True)\n",
    "        kg_index.storage_context.persist(persist_dir=os.path.join(persist_dir, \"kg\"))\n",
    "        \n",
    "        print(f\"Index built and saved to {persist_dir} / İndeks oluşturuldu ve {persist_dir} dizinine kaydedildi\")\n",
    "        \n",
    "        return kg_index\n",
    "    else:\n",
    "        print(f\"Loading existing index from {persist_dir}... / {persist_dir} dizininden mevcut indeks yükleniyor...\")\n",
    "        \n",
    "        # Load the indices from storage / Depodan indeksleri yükle\n",
    "        kg_storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=os.path.join(persist_dir, \"kg\")\n",
    "        )\n",
    "        kg_index = load_index_from_storage(storage_context=kg_storage_context)\n",
    "        \n",
    "        print(\"Index loaded successfully / İndeks başarıyla yüklendi\")\n",
    "        \n",
    "        return kg_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_engine(kg_index):\n",
    "    \"\"\"\n",
    "    Create a hybrid query engine that combines graph and vector search\n",
    "    \n",
    "    Args:\n",
    "        kg_index: Knowledge graph index\n",
    "        \n",
    "    Returns:\n",
    "        query_engine: A hybrid query engine\n",
    "    \"\"\"\n",
    "    # Create query engines for both indices\n",
    "    # Her iki indeks için de sorgu motorları oluştur\n",
    "    kg_query_engine = kg_index.as_query_engine(\n",
    "        response_mode=\"compact\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return kg_query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new index from data...\n",
      "Loaded 13 documents from data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice built and saved to storage\n"
     ]
    }
   ],
   "source": [
    "# Build or load the indices / indeksleri oluştur veya yükle\n",
    "kg_index = build_graph_rag(data_dir=\"data\", rebuild=False)\n",
    "\n",
    "# Create a hybrid query engine / Hibrit bir sorgu motoru oluştur\n",
    "query_engine = create_query_engine(kg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32mExtracted keywords: ['AI', 'is', 'What']\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 03508ead-34f9-4a25-9bc7-6acc8ec4cc82: AI continues to evolve rapidly, with advancements in general AI, explainable ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 56a0507c-7ae5-43b1-83d3-ed05dcd47b84: Autonomous systems, such as self-driving cars and drones, rely on AI to navig...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5ca239b4-f2ba-4946-ad73-b5f057a12753: Machine learning (ML) is a subset of AI that enables systems to learn from da...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 78f465a4-7967-4e9d-ae77-e56e89290117: AI is transforming healthcare by improving diagnostics, automating administra...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2649ae2a-a793-49a8-8fe6-6524325999cc: The concept of AI dates back to ancient myths and early philosophical discuss...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2599601e-a67e-496e-b9b7-afa45e3689ed: While AI offers many benefits, it also raises ethical concerns. Bias in AI mo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: fb4be5da-4b5d-4c2e-9816-f0646633adaa: AI is rapidly evolving with trends like multimodal learning, smaller efficien...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 25560186-bbcb-4ba0-9467-ebcd8a642f7e: Rather than replacing humans, AI is often designed to augment human capabilit...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5feaf910-de77-4faf-a6ed-12a280186e11: Businesses leverage AI to optimize operations, detect fraud, and enhance cust...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 06393edd-6e07-4571-bc07-866567ffd219: AI is revolutionizing healthcare by improving diagnostics, predicting disease...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "('Ai', 'Has advancements in', 'Explainable ai')\n",
      "('Machine learning', 'Is a subset of', 'Ai')\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      "AI, or Artificial Intelligence, is a field of study that dates back to ancient times but became formalized in the 1950s. It involves creating systems that can perform tasks that would normally require human intelligence. This includes tasks like understanding natural language, recognizing patterns, and making decisions. Modern AI leverages deep learning and neural networks to achieve impressive levels of intelligence. It has a wide range of applications, from powering autonomous systems like self-driving cars and drones to transforming healthcare by improving diagnostics and personalizing treatment. AI is also used in businesses to optimize operations and enhance customer service. However, it also raises ethical concerns such as bias, data privacy, and the impact on employment. The future of AI is rapidly evolving, with advancements in areas like general AI, explainable AI, and AI-human collaboration.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is AI?\"\n",
    "    \n",
    "response = query_engine.query(query)\n",
    "print(f\"\\nResponse:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
