{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env dosyası içerisinde gerekli olan keyler alınır / Required keys are retrieved from the .env file\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Key bilgisi sağlamanın diğer yolu / Another way to provide the key\n",
    "\n",
    "# import openai\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenticRAGSystem:\n",
    "    def __init__(self, data_folder: str):\n",
    "        \"\"\"Initialize the Agentic RAG system with LlamaIndex using OpenAI.\"\"\" # LlamaIndex ile OpenAI kullanarak Agentic RAG sistemini başlatır\n",
    "        # LLM ve gömme modelleri ayarlanır / Set up LLM and embeddings\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.embed_model = OpenAIEmbedding()\n",
    "        Settings.llm = self.llm\n",
    "        Settings.embed_model = self.embed_model\n",
    "        \n",
    "        # Düğüm ayrıştırıcı ayarlanır / Set up node parser\n",
    "        self.node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=200)\n",
    "        Settings.node_parser = self.node_parser\n",
    "        \n",
    "        # Belgeler yüklenir ve indekslenir / Load and index documents\n",
    "        self.documents = self._load_documents(data_folder)\n",
    "        self.index = self._create_index()\n",
    "        \n",
    "        # Sorgu motoru ayarlanır / Set up query engine\n",
    "        self.query_engine = self._setup_query_engine()\n",
    "        \n",
    "        # Ajan ayarlanır / Set up agent\n",
    "        self.agent = self._setup_agent()\n",
    "    \n",
    "    def _load_documents(self, data_folder: str):\n",
    "        \"\"\"Load documents from the data folder.\"\"\" # Veri klasöründen belgeleri yükler\n",
    "        if not os.path.exists(data_folder):\n",
    "            raise FileNotFoundError(f\"Veri klasörü '{data_folder}' bulunamadı / Data folder '{data_folder}' not found.\")\n",
    "        \n",
    "        # Belgeleri doğru yöntemle yükler / Load documents with the correct method\n",
    "        reader = SimpleDirectoryReader(input_dir=data_folder)\n",
    "        return reader.load_data()\n",
    "    \n",
    "    def _create_index(self):\n",
    "        \"\"\"Create vector index from documents.\"\"\" # Belgelerden vektör indeksi oluşturur\n",
    "        return VectorStoreIndex.from_documents(self.documents)\n",
    "    \n",
    "    def _setup_query_engine(self):\n",
    "        \"\"\"Set up an advanced query engine with similarity filtering.\"\"\" # Benzerlik filtreleme ile gelişmiş bir sorgu motoru ayarlar\n",
    "        # Parametrelerle alıcı oluşturur / Create retriever with parameters\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=self.index,\n",
    "            similarity_top_k=3\n",
    "        )\n",
    "        \n",
    "        # Daha iyi sonuçlar için son işlem ekler / Add post-processing for better results\n",
    "        postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "        \n",
    "        # max_tokens parametresi olmadan yanıt sentezleyici oluşturur / Create response synthesizer without max_tokens parameter\n",
    "        response_synthesizer = CompactAndRefine()\n",
    "        \n",
    "        # Sorgu motorunu oluşturur / Build query engine\n",
    "        return RetrieverQueryEngine(\n",
    "            retriever=retriever,\n",
    "            response_synthesizer=response_synthesizer,\n",
    "            node_postprocessors=[postprocessor]\n",
    "        )\n",
    "    \n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Set up a ReAct agent with tools.\"\"\" # Araçlarla bir ReAct ajanı ayarlar\n",
    "        # Ajan için araçlar oluşturur / Create tools for the agent\n",
    "        query_tool = QueryEngineTool(\n",
    "            query_engine=self.query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"document_search\",\n",
    "                description=\"Search and analyze the documents to answer questions about their content.\" # Belgeleri arayın ve içerikleri hakkında soruları yanıtlamak için analiz edin.\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # ReAct ajanı oluşturur / Create ReAct agent\n",
    "        return ReActAgent.from_tools(\n",
    "            [query_tool],\n",
    "            llm=self.llm,\n",
    "            verbose=True\n",
    "        )\n",
    "    \n",
    "    def query(self, query_text: str) -> str:\n",
    "        \"\"\"Process a query through the agentic system.\"\"\" # Sorguyu ajansız sistem üzerinden işler\n",
    "        return self.agent.query(query_text)\n",
    "    \n",
    "    def search_documents(self, query_text: str) -> str:\n",
    "        \"\"\"Direct search through the query engine (non-agentic).\"\"\" # Sorgu motoru üzerinden doğrudan arama yapar (ajansız)\n",
    "        return self.query_engine.query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG sistemini başlat / Initialize the RAG system\n",
    "rag_system = AgenticRAGSystem(\n",
    "    data_folder=DATA_FOLDER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the history of AI?\n",
      "> Running step 20691379-57bf-40e5-b768-57340299a894. Step input: What is the history of AI?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: document_search\n",
      "Action Input: {'input': 'history of AI'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The history of AI traces back to ancient myths and philosophical discussions, but it formally emerged as a field of study in the 1950s. Early models were primarily rule-based systems. Over time, advancements led to the development of deep learning and neural networks, significantly enhancing AI's capabilities. Notable milestones include IBM's Deep Blue defeating a chess champion and the creation of systems like ChatGPT that can generate human-like text.\n",
      "\u001b[0m> Running step dd5f4bb3-1807-4f25-ac55-c791fb2f662a. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The history of AI traces back to ancient myths and philosophical discussions, but it formally emerged as a field of study in the 1950s. Early models were primarily rule-based systems. Over time, advancements led to the development of deep learning and neural networks, significantly enhancing AI's capabilities. Notable milestones include IBM's Deep Blue defeating a chess champion and the creation of systems like ChatGPT that can generate human-like text.\n",
      "\u001b[0mResponse: The history of AI traces back to ancient myths and philosophical discussions, but it formally emerged as a field of study in the 1950s. Early models were primarily rule-based systems. Over time, advancements led to the development of deep learning and neural networks, significantly enhancing AI's capabilities. Notable milestones include IBM's Deep Blue defeating a chess champion and the creation of systems like ChatGPT that can generate human-like text.\n"
     ]
    }
   ],
   "source": [
    "# Örnek sorgu / Example query\n",
    "query = \"What is the history of AI?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Sorgu motorundan yanıt alın / Get response from the query engine\n",
    "response = rag_system.query(query)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the history of AI?\n",
      "Response: The history of AI dates back to ancient myths and early philosophical discussions, but it became a formal field of study in the 1950s. Initially, early AI models focused on rule-based systems. Over time, advancements led to the development of modern AI, which utilizes deep learning and neural networks. Significant milestones include IBM's Deep Blue defeating a chess champion and the emergence of systems like ChatGPT that can generate human-like text.\n"
     ]
    }
   ],
   "source": [
    "# Örnek sorgu / Example query\n",
    "query = \"What is the history of AI?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Sorgu motorundan yanıt alın / Get response from the query engine\n",
    "response = rag_system.search_documents(query)\n",
    "print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
